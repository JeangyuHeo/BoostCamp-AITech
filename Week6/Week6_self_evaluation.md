## 주간 학습 정리



#### 1. 강의 복습 내용

Day1 : https://github.com/JeangyuHeo/BoostCamp-AITech/blob/main/Week6/Day1_Intro_to_NLP.md

Day2 : https://github.com/JeangyuHeo/BoostCamp-AITech/blob/main/Week6/Day2_Basic_RNN.md

Day3 : https://github.com/JeangyuHeo/BoostCamp-AITech/blob/main/Week6/Day3_Seq_to_Seq.md

Day4 : https://github.com/JeangyuHeo/BoostCamp-AITech/blob/main/Week6/Day4_BeamSearch_BLEU.md



#### 2. 과제 수행 과정 / 결과물 정리

과제는 별로 없었으나, 실습 코드가 있었다. 실습 코드를 전부 이해하고 과제를 진행하여 큰 어려움없이 해결 할 수 있었다. 처음에는 기존에 진행해왔던 CNN과 접근하는 방법부터 달라서 많이 헷갈렸지만, 비슷한 과정을 직전에 해서 그런지 금방 이해하고 진행 할 수 있었다. 가장 기본적인 word2vec부터 시작하여 RNN 기본 동작 구조, data preprocess 과정, huggingface 사용법 등 다양한 과정을 공부 할 수 있었다. 코딩하는 과정 속에서 쉴새없이 변하는 차원을 이해하는게 가장 어려웠던 것 같다.



#### 3. 피어세션 정리

1. 피어세션에서는 수업 도중에 어려웠던 내용이나, 과제를 하다가 어려웠던 부분을 물어볼 수 있었다. 

   * embedding size의 의미
   * subword tokenization을 쓰면 word vector가 작아지는 이유
   * RNN 동작 과정 속에서의 궁금증들

2. 논문을 읽고 차례대로 발표하는 시간을 가졌다.

   * GloVe: Global Vectors for Word Representation
   * Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
   * Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation

   를 읽었다.

   



#### 4. 학습 회고

주재걸 교수님의 수업이 개인적으로 잘 맞아서 수업을 듣는 시간이 굉장히 유익하고 재밌었다. 기초적인 용어라도 다 설명해주셔서 듣기가 참 편했다. 저번에 한번 듣고 공부했던 내용이라 더 쉬웠고, 즐길 수 있었다. 코드를 한줄한줄 이해하는데, 놓치는게 무서웠지만 다시 한번 작은 것보단 큰 것을 가져가자는 자기 다짐을 하면서 넘어 갈 수 있었다. 

새로운 팀이 만들어졌다. 너무너무 좋은 사람들이고, 실력들도 너무 좋은 사람들이라 못따라갈까 걱정이 됐다. 하지만, 나도 열심히 공부해서 팀원들도 나에게서 많은 것을 배워갈 수 있도록 해야겠다. 행복하고, 걱정도 많고 즐거운 주였다.

